\chapter{Условное математическое ожидание}

В этой главе мы рассмотрим понятие условного математического ожидания, которое представляет собой важную основу не только для анализа статистических методов, но и в общей сложности для стохастической теории.

\begin{rmrk} Рассмотрим интегрируемую случайную величину: $ X: (\Omega, \mathcal{A}, \MP) \rightarrow (\MR, \mathcal{B})$. После проведения эксперимента и наблюдения результата информация о случайной величине полностью известна:
	\[ \omega \mapsto X(\omega). \]
	Перед проведением эксперимента неизвестно ничего о его итоге. В такой ситуации лучший способ предсказать его -- это использование математического ожидания:
	\[ 	\omega \mapsto \ME[X](\omega) \]
	
	Условное математическое ожидание -- лучшая аппроксимация случайной величины $X$, при условии что часть информации о ней известна.
	\end{rmrk}

\begin{defn} Пусть $(\Omega, \mathcal{A})$ -- измеримое пространство с заданными мерами $\mu$ и $\nu$. Мера $\nu$ называется  \textbf{\textit{абсолютно непрерывной}} относительно $\mu$ (или же $\mu$ доминирует $\nu$), если
	\[\mu(A) = 0 \Longrightarrow \nu(A)=0 \quad \forall A \in \mathcal{A}.\]
	
	Обозначение: $\nu \ll \mu$.
\end{defn}


\begin{thm}[\textbf{Теорема Радона-Никодима}] \label{Radon Nikodym}
	 Пусть $(\Omega, \mathcal{A})$ -- измеримое пространство с заданными мерами $\mu$ и $\nu$. Если $\mu$ $\sigma$-конечная, то следующие утверждения эквивалентны:
	\begin{enumerate}
		\item $\nu \ll \mu$.
		\item Существует $\mathcal{A}$-измеримая неотрицательная функция $f$, такая что:
		\[\nu(A)=\int_{A} f d\mu \quad \forall A \in \mathcal{A}.\]
		Иначе говоря, $\nu$ обладает плотностью $f$ по $\mu$. В качестве обозначения плотности часто используется т.н. \textbf{\textit{производная Радона-Никодима}}:
		\[ f=\frac{d\nu}{d\mu}. \]
    \end{enumerate}
	\end{thm}
\begin{proof}
	Теорема 17.10 в \cite{Bauer}.
\end{proof}

\begin{defn}\label{Conditional expectation}
	Пусть $\mathcal{F} \subset \mathcal{A}$ -- $\sigma$-алгебра. Случайная величина $Y: (\Omega, \mathcal{A}, \MP) \rightarrow (\MR, \mathcal{B})$ называется \textbf{\textit{условным математическим ожиданием}} $X$ относительно $\mathcal{F}$, если:
	\begin{enumerate}
		\item $Y$ $\mathcal{F}$-$\mathcal{B}$-измеримая\footnote{$Y^{-1}(B) \in \mathcal{F} \quad \forall B \in \mathcal{B}$},
		\item $\ME[X 1_{A}]=\ME[Y 1_{A}] \quad \forall A \in \mathcal{F}$ .
	\end{enumerate}
\end{defn}

\begin{thm}\label{Existence and uniqueness of expectation}
	Условное математическое ожидание $X$ относительно $\mathcal{F}$ существует и единственно почти всюду.
\end{thm}

\begin{proof}
	\textit{Единственность.} Пусть $Y$ и $\overline{Y}$ -- два условных математических ожидания. Зададим множество $A=\{\omega \mid Y(\omega) > \overline{Y}({\omega}) \}$. Тогда согласно Определению \ref{Conditional expectation} (ii):
	\[\ME[(Y-\overline{Y})1_A]=\ME[Y1_A]-\ME[\overline{Y}1_A]=0.   \]
	Так как $(Y-\overline{Y})1_A \geq 0$, то $\MP(A)=0$. Таким же образом доказывается, что $\MP(Y<\overline{Y})=0$.
	
	\textit{Существование.} Представим $X=X^+-X^-$ в виде разницы положительной и отрицательной случайных величин. Зададим две меры на $(\Omega, \mathcal{F})$:
	\[\mathbb{Q}^{\pm}(A)=\ME[X^\pm 1_A],  \quad A \in \mathcal{F}.\]
	Они обе абсолютно непрерывны относительно меры $\MP$. По Теореме \ref{Radon Nikodym} существуют $\mathcal{F}$-измеримые плотности $Y^\pm$, такие что
	\[\mathbb{Q}^{\pm}(A)=\int_A Y^\pm d\MP = \ME[Y^\pm 1_A].\]
	В таком случае, $Y = Y^+-Y^-$ -- условное математическое ожидание.	
\end{proof}

\begin{rmrk}
	Для условного математического ожидания $X$ относительно $\mathcal{F}$ мы будем использовать обозначение $Y=\ME[X | \mathcal{F}]$, что в соответствии с предыдущей теоремой должно пониматься как равенство $\MP$-почти наверное. Если $X=1_C$ для $C \in \mathcal{A}$, то условная вероятность $X$ при условии $\mathcal{F}$:
	\[\MP(C|\mathcal{F})=\ME[1_C|\mathcal{F}].\]
\end{rmrk}

\begin{defn}
	Пусть $Y$ -- случайная величина (не обязательно интегригруемая) в пространстве $(\Omega, \mathcal{A}, \MP)$. Тогда \textbf{\textit{условное ожидание $X$ относительно $Y$}}:
	\[ \ME[X|Y]=\ME[X|\sigma(Y)], \]
	где $\sigma(Y)$ обозначает $\sigma$-алгебру, порожденную $Y$.
\end{defn}

\begin{lmm} \label{Properties of conditional expectation}
	Пусть $(\Omega, \mathcal{A}, \MP)$ -- вероятностное пространство, $\mathcal{F} \subset \mathcal{A}$ -- $\sigma$-алгебра и $X$, $Y$ -- интегрируемые случайные величины, принимающие действительные значения. Тогда выполняются следующие свойства:
	\begin{enumerate}
		\item \textbf{Линейность}. Для любых $\alpha, \beta \in \MR$:
		\[ \ME[\alpha X + \beta Y | \mathcal{F}]=\alpha \ME[X|\mathcal{F}]+\beta \ME[Y|\mathcal{F}]. \]
		\item \textbf{Монотонность}. Если $X \leq Y$ $\MP$-п.н., то $\ME[X|\mathcal{F}] \leq \ME[Y|\mathcal{F}]$ $\MP$-п.н.
	\end{enumerate}
\end{lmm}
\begin{proof}
		\begin{enumerate}
		\item Правая часть равенства $\mathcal{F}$-измерима. Следовательно, для любого множества $A \in \mathcal{F}$:
		\[ \ME[(\alpha X + \beta Y)1_A]=\alpha \ME[1_A X]+\beta \ME[1_A Y]=\ME[1_A(\alpha \ME[X|\mathcal{F}] + \beta \ME[Y|\mathcal{F}])]. \]
		\item Зададим множество $ A= \{ \ME[X|\mathcal{F}] - \ME[Y|\mathcal{F}] <0 \} \in \mathcal{F}$. Тогда:
		\[ 0 \geq \int_A (\ME[X|\mathcal{F}] - \ME[Y|\mathcal{F}]) d\MP = \int_A \ME[X-Y|\mathcal{F}]d\MP = \int_A (X-Y) d\MP \geq 0. \]
		Следовательно, $\MP(A)=0$.
	\end{enumerate}
\end{proof}

\begin{exmp} \
	\begin{enumerate}
		\item Если $\mathcal{F}= \{\emptyset, \Omega \}$, то $\ME[X|\mathcal{F}]$ по определению постоянная и с выбором $A=\Omega$ в (ii) следует:
		\[\ME[X | \mathcal{F}]=\ME[X]. \]
		Это соответствует ситуации, когда никакой дополнительной информации об итоге эксперимента не известно.
		\item Если $\sigma(X) \subset \mathcal{F}$, то $\ME[X|\mathcal{F}]=X$.
		\item Пусть множество $A \in \mathcal{A}$, $\MP(A) \in (0, 1)$ и $\mathcal{F}=\sigma(A)=\{\Omega, A, A^c, \emptyset \}$. Вследствие $\mathcal{F}$-измеримости условное ожидание $\ME[X|A]$ является постоянной:
		\[\ME[X|A]=\Big(\MP(A)^{-1} \int_A X d\MP\Big)1_A + \Big(\MP(A^c)^{-1} \int_{A^c} X d\MP\Big)1_{A^c}. \]
		В случае, если семейство элементарных событий составляют непересекающиеся множества $(\Omega = A_1 \cup \dots A_n)$ c положительными вероятностями, то:
		\[\ME[X|A_1, \dots , A_n] = \sum_{i=1}^n \Big(\MP(A_i)^{-1} \int_{A_i} X d\MP\Big)1_{A_i}. \]
	\end{enumerate}
\end{exmp}

\begin{thm}[\textbf{Монотонная сходимость}] \label{Monotone convergence}
	Пусть $X_n \geq 0$ -- последовательность интегрируемых случайных величин, такая что $X_n \nearrow X$. Тогда существует $\mathcal{F}$-измеримая случайная величина $Y$, такая что $\ME[X_n|\mathcal{F}] \nearrow Y$. В частности,
	\[ \ME[X1_A]=\ME[Y1_a] \quad \forall A \in \mathcal{F}, \]
	и это выполняется, если $X$ интегрируемая в понимании обычного условного математичесого ожидания.
\end{thm}

\begin{proof}
	По свойству монотонности математического ожидания последовательность $\ME[X_n|\mathcal{F}]$ возрастает. Следовательно, $Y$ -- поточечный предел последовательности $\mathcal{F}$-измеримых функций, который также $\mathcal{F}$-измеримый. В дополнение, так как $X_n \nearrow X$, то $X_n1_A \nearrow X1_A$, и мы получаем классическую теорему о монотонной сходимости:
	\[ \ME[X1_A]=\lim\limits_{n \rightarrow \infty}\ME[X_n1_A]=\lim\limits_{n \rightarrow \infty}\ME[\ME[X_n|\mathcal{F}]|1_A]=\ME[Y1_A]. \]
\end{proof}

\begin{rmrk} \
	\begin{enumerate}
		\item Теорема \ref{Monotone convergence} также показывает, что условное математическое ожидание существует для $X$, если задать последовательность $X_n=\min(X,n)$.
		\item Лемма \ref{Properties of conditional expectation} и Теорема \ref{Monotone convergence} доказывают лишь некоторые свойства ожидаемых значений, которые могут быть обобщены до условных ожиданий. Последующие примеры включают неравенство Коши-Шварца, неравенство Йенсена и вариант теоремы о мажорируемой сходимости.
	\end{enumerate}
\end{rmrk}

\begin{thm} \label{Factorization theorem}
	Пусть $X$ и $Y$  -- случайные величины, такие что $\ME[|X|]<\infty$, $\ME[|XY|]<\infty$ и $Y$ $\mathcal{F}$-измеримая, тогда
	\[ \ME[XY | \mathcal{F}]=Y\ME[X|\mathcal{F}].  \]
	Другими словами, мы вытаскиваем из-под условного математического ожидания все, что известно.
\end{thm}

\begin{proof}
	Случайная величина $Y\ME[X|\mathcal{F}]$ $\mathcal{F}$-измеримая. Остается доказать:
	\[\ME[XY1_A]=\ME[Y\ME[X|\mathcal{F}]1_A] \quad \forall A \in \mathcal{F}. \]	
	Используем индукцию из теории меры:
	\begin{enumerate}
		\item Пусть $Y=1_B$, $B \subset \mathcal{F}$. Тогда
		\[ \ME[XY1_A] = \ME[X1_{A \cap  B}] = \ME[\ME[X|\mathcal{F}]1_{A \cap  B}]=\ME[Y\ME[X|\mathcal{F}]1_A]. \]
		\item Обобщаем равенство до ступенчатых функций и используем свойство линейности (Лемма \ref{Properties of conditional expectation}).
		\item Для $X \geq 0$ и $Y \geq 0$ используем (ii) и монотонную сходимость (Теорема \ref{Monotone convergence}).
		\item Раскладываем случайные величины $X$ и $Y$ на положительную и отрицательную части: $X=X^+-X^-$ и $Y=Y^+-Y^-$.
	\end{enumerate}
\end{proof}

\begin{thm} [\textbf{Башенное свойство}] \label{Tower property}
	Пусть $X$ -- интегрируемая случайная величина на $(\Omega, \mathcal{A}, \MP)$ и $\mathcal{F}_1, \mathcal{F}_2$ -- $\sigma$-алгебры, такие что $\mathcal{F}_1 \subset \mathcal{F}_2 \subset \mathcal{A}$. Тогда
	\[ \ME[\ME[X|\mathcal{F}_2]|\mathcal{F}_1] = \ME[X|\mathcal{F}_1]=\ME[\ME[X|\mathcal{F}_1]\mathcal{F}_2]. \]
\end{thm}
	
\begin{proof}
	Первое равенство: для любого множества $A \in \mathcal{F}_1$
	\[ \int_{A}\ME[\ME[X|\mathcal{F}_2]|\mathcal{F}_1] d\MP = \int_A \ME[X|\mathcal{F}_2] d\MP=\int_AXd\MP=\int_A\ME[X|\mathcal{F}_1]d\MP. \]
	Второе равенство следует из Теоремы \ref{Factorization theorem}, так как случайная величина $\ME[X|\mathcal{F}_1]$ $\mathcal{F}_2$-измерима.
\end{proof}

\begin{thm}[\textbf{Независимость}] \label{Independence}
	Пусть $X$ -- интегрируемая случайная величина и $\mathcal{F}, \mathcal{G} \subset \mathcal{A}$ -- $\sigma$-алгебры, такие что $\mathcal{G}$ и $\sigma(\sigma(X), \mathcal{F})$ независимы. Тогда:
	\[ \ME[X|\sigma(\mathcal{F}, \mathcal{G})] = \ME[X|\mathcal{F}]. \]
\end{thm}
\begin{proof}
	Условное ожидание $\ME[X|\mathcal{F}]$ $\sigma(\mathcal{F},\mathcal{G})$-измеримое. Остается показать, что
	\[ \ME[X1_A]=\ME[\ME[X|\mathcal{F}]|1_A] \quad \forall A \in \sigma(\mathcal{F},\mathcal{G}). \]
	Все множества, удовлетворяющие этому равенству составляют систему Динкина\footnote{Семейство $\mathcal{D}$ подмножеств множества $\Omega$ называется \textbf{\textit{системой Динкина}} (или \textbf{\textit{$\lambda$-системой}}), если оно удовлетворяет следующим свойствам:
		\begin{enumerate}
			\item $\Omega \in \mathcal{D},$
			\item $A \in \mathcal{D} \Longrightarrow A^c \in \mathcal{D},$
			\item Если $A_1, A_2,... \in \mathcal{D}$ -- непересекающиеся множества, то $\cup_{n=1}^\infty A_n \in \mathcal{D}.$
		\end{enumerate}
		Иными словами, система Динкина, замкнутая относительно конечного числа пересечений, образует $\sigma$-алгебру.
		}. Нужно показать, что семейство этих множеств замкнуто относительно операции пересечения. Пусть $F \in \mathcal{F}$ и $D \in \mathcal{D}$, тогда:
	\[ \ME[X1_{F \cap G}]=\ME[1_G(1_FX)]=\ME[1_G]\ME[1_FX]=\ME[1_G]\ME[\ME[X|\mathcal{F}]1_F]=\ME[\ME[X|\mathcal{F}]1_{F \cap G}]. \]
\end{proof}

\begin{crlr} \label{crlr1.15}
	Пусть $X \in L^1(\Omega, \mathcal{A}, \MP)$ и $\mathcal{H} \subset \mathcal{A}$ -- $\sigma$-алгебра. Тогда:
	\begin{enumerate}
		\item $\ME[\ME[X|\mathcal{H}]]=\ME[X]$ (итерированное ожидание).
		\item Если $X$ не зависит от $\mathcal{H}$, то $\ME[X|\mathcal{H}]=\ME[X]$.
	\end{enumerate}
\end{crlr}
\begin{proof}
		\begin{enumerate}
			\item Теорема \ref{Tower property} для $\mathcal{F}_1=\{\Omega, \emptyset\}$.
			\item Теорема \ref{Independence} для $\mathcal{F}=\{\Omega, \emptyset\}$ и $\mathcal{G}=\mathcal{H}$.
		\end{enumerate}
\end{proof}

\begin{exmp} \label{exmp1.16} \
	\begin{enumerate}
		\item Предположим, что $X$ и $Y$ дискретные случайные величины, т.е. существуют счетные подмножетсва $I_X, I_Y \subset \MR$, такие что $\MP(X \in I_X)=\MP(Y \in I_Y)=1$. Зададим для $x \in I_X$ и $y \in I_y$ условную вероятность (при $\MP(Y=y)>0$):
		\[ \MP(X=x\ |\ Y=y)=\frac{\MP(X=x, Y=y)}{\MP(Y=y)}=:\frac{p_{xy}}{p_y}.\]
		Тогда $\ME[X|Y]=g(Y)$ (если $X \in L^1(\Omega, \mathcal{A}, \MP)$), где
		\[ g(y) :
		\left \{
		\begin{array}{ll}
		\sum_{x \in I_X} x \frac{p_{xy}}{p_y}, & p_y>0, \\
		0, & p_y=0.
		\end{array}
		\right.
		\]
		\item Предположим, что $X$ и $Y$ имеют плотность $f_{X,Y}(x,y)$ относительно меры Лебега. Функции
		\[ f_X(x)=\int f_{X,Y}(x,y)dy \quad \text{и} \quad f_Y(y)=\int f_{X,Y}(x,y)dx \]
		называются \textbf{\textit{маргинальными плотностями}}. Если мы зададим
		\[ g(y) :
		\left \{
		\begin{array}{ll}
		\int x \frac{f_{X,Y}(x,y)}{f_Y(y)}dx, & f_Y(y)>0, \\
		0, & f_Y(y)=0,
		\end{array}
		\right.
		\]
		то $\ME[X|Y]=g(Y)$.
	\end{enumerate}
\end{exmp}
\begin{proof}
		\begin{enumerate}
		\item Функция $g(Y)=\sigma(Y)$-измеримая, так как она является измеримой по Борелю. Также пусть $B \in \mathcal{B}$ и $F=\{ Y \in B \} \in \sigma(Y)$. Тогда
		\[ \ME[g(Y)1_F]=\sum_{y \in B \cap I_y} \sum_{x \in I_x} x \frac{p_{xy}}{p_y}1_{\{p_y > 0\}}p_y = \sum_{x \in I_x} \sum_{y \in B \cap I_y} x p_{xy} = \ME[X1_F]. \]
		
		\item По теореме Фубини\footnote{
			Пусть даны два пространства с $\sigma$-конечными мерами $(X_1, \mathcal{F}_1, \mu_1)$ и $(X_2, \mathcal{F}_2, \mu_2)$. Обозначим через  $(X_1 \times X_2, \mathcal{F}_1 \otimes \mathcal{F}_2, \mu_1 \otimes \mu_2)$ их произведение. Пусть функция $f \colon X_1 \times X_2 \to \MR$ интегрируема относительно меры $\mu_1 \otimes \mu_2$. Тогда
			\begin{enumerate}
				\item Функция $x_1 \mapsto \int \limits_{X_2} f(x_1, x_2) \mu_2 (dx_2)$ определена и интегрируема относительно $\mu_1$.
				\item Функция $x_2 \mapsto \int \limits_{X_1} f(x_1, x_2) \mu_1 (dx_1)$ определена и интегрируема относительно $\mu_2$.
				\item $\iint \limits_{X_1 \times X_2} f(x_1, x_2) \mu_1 \otimes \mu_2(dx_1, dx_2) = \int \limits_{X_1} \int \limits_{X_2} f(x_1, x_2) \mu_2(dx_2) \mu_1(dx_1) = \int \limits_{X_2} \int \limits_{X_1} f(x_1, x_2) \mu_1(dx_1) \mu_2(dx_2).$
		    \end{enumerate}
			} имеет место измеримость $y \mapsto \int x f(x, y) dx$ и $y \mapsto \int f(x, y)dx$. Следовательно, $g$ измерима. В заключение, пусть $F = \{Y \in B\} \in \sigma(Y)$. Тогда,
		\[ \begin{aligned}
		\ME[g(Y)1_F] & = \int_B g(y) f_Y(y) 1_{\{f_Y(y) > 0 \}} dy \\
		& = \int_B \frac{\int x f_{X, Y}(x,y) dx}{f_Y(y)} f_Y(y) 1_{\{f_Y(y) > 0 \}} dy \\
		\text{т. Фубини} \rightarrow & = \int x \int_B 1_{\{f_Y(y) > 0 \}} f_{X, Y}(x, y) dy dx = \ME[X 1_F].
	    \end{aligned}	\]
	\end{enumerate}
\end{proof}

\begin{rmrk}
	В предыдущем примере мы увидели, что $\ME[X|Y]$ принимает форму функции $g(Y)$, где $g$ -- измеримая функция. Это необходимое свойство.
\end{rmrk}

\begin{thm} [\textbf{Лемма о факторизации}] \label{Factorization lemma}
	Пусть $Y:\Omega \rightarrow \Omega'$ $\mathcal{A}$-$\mathcal{A}'$-измерима и $Z: \Omega \rightarrow \overline{\MR}$ $\mathcal{A}$-$\overline{\mathcal{B}}$-измерима. Тогда $Z$ $\sigma(Y)$-$\overline{\mathcal{B}}$-измерима тогда и только тогда, когда существует $\mathcal{A}'$-$\overline{\mathcal{B}}$-измеримая функция $g:\Omega' \rightarrow \overline{\MR}$, такая что $Z = g \circ Y$.
\end{thm}
\begin{proof} \\
	
	''$\Longleftarrow$'' $Y$ $\sigma(Y)$-$\mathcal{A}'$-измерима и $g$ $\mathcal{A}'$-$\overline{\mathcal{B}}$-измерима. Следовательно, $g \circ Y$ $\sigma(Y)$-$\overline{\mathcal{B}}$-измерима. \\
	
	''$\Longrightarrow$'' Пусть $Z = \sum_{i=1}^n \alpha_i 1_{A_i}$, где $A_i \in \sigma(Y)$. Тогда, существуют $A_i' \in \mathcal{A}_i'$, такие что $A_i = Y^{-1}(A_i')$. Тогда, пусть $g = \sum_{i=1}^n \alpha_i 1_{A_i'}$. В общем случае, любая $\sigma(Y)$-$\overline{\mathcal{B}}$-измеримая функция $Z$ является пределом таких элементарных функций.
\end{proof}

\begin{thm}
	Пусть $X:\Omega \rightarrow \MR$ и $Y:\Omega \rightarrow \Omega'$ -- случайные величины и $\ME[X] < \infty$. Тогда любая $\mathcal{A}$-$\mathcal{B}$-измеримая функция $g:\Omega' \rightarrow \MR$, такая что $\ME[X|Y]=g(Y)$ $\MP^Y$-интегрируема, удовлетворяет
	\begin{equation} \label{1.1}
		\int_{A'} g d\MP^Y = \int_{\{Y \in A' \}} X d\MP \quad  \forall A' \in \mathcal{A}'
	\end{equation}
	и $\MP^Y$-п.н. единственная. И наоборот, если $g:\Omega' \rightarrow \MR$ $\mathcal{A}$-$\mathcal{B}$-измерима и удовлетворяет (\ref{1.1}), то $g(Y)$ -- версия\footnote{Версия от версии отличается не более чем на множестве нулевой меры Лебега.} математического ожидания.
\end{thm}
\begin{proof} \\
	
	''$\Longrightarrow$'' Для любого $A' \in \mathcal{A}'$ имеет место
	\[ \int_{\{Y \in A'\}} X d\MP = \int_{\{Y \in A'\}} \ME[X|Y]d\MP = \int_{\{Y \in A'\}} g \circ Y d\MP = \int_{A'}gd\MP^Y. \]
	$\MP^Y$-интегрируемость $g$ следует из (\ref{1.1}). Предположим, что $\ME[X|Y]=h(Y)$, тогда
	\[ \int_{A'}gd\MP^Y = \int_{A'} h d\MP^Y \quad \forall A'\in \mathcal{A}', \]
	вследствие (\ref{1.1}). Разложив функции на положительные и отрицательные части:
	\[ g = g^+ - g^- \quad \text{и} \quad h = h^+ - h^-, \]
	получаем
	\[ \int_{A'} (g^+ + h^-)d\MP^Y=\int_{A'} (h^+ + g^-)d\MP^Y \quad \forall A' \in \mathcal{A}'. \]
	Как и в доказательстве Теоремы \ref{Existence and uniqueness of expectation}:
	\[ g^+ + h^- = h^+ + g^- \quad \MP^Y-\text{п.н.} \quad \Rightarrow \quad g^+ - g^- = h^+-h^-\quad \MP^Y-\text{п.н.} \]

	''$\Longleftarrow$'' $g \circ Y$ $\sigma(Y)$-$\overline{\mathcal{B}}$-измеримая по определению. Используя замену переменных и (\ref{1.1}), мы получаем:
	\[ \int_{\{Y\in A'\}} g \circ Y d\MP = \int_{A'} g d\MP^Y =\int \limits_{\{Y\in A'\}} X d\MP \quad \forall A' \in \mathcal{A}'.  \]
	Следовательно,
	\[ \int_C g \circ Y d \MP = \int_C X d\MP \quad \forall C \in \sigma(Y) \]
	и также $g \circ Y = \ME[X|Y]$.
\end{proof}

\begin{exmp}
	Рассмотрим $(\Omega', \mathcal{A}')$, где $\{y\} \in \mathcal{A}'$ для определенного события $y \in \Omega'$. В этом случае (\ref{1.1}) следует читать следующим образом:
	\[ \int_{\{y\}} g d\MP^Y = g(y) \MP(Y = y) = \int_{\{Y = y\}} X d\MP. \]
	Если $\MP(Y=y)>0$, то
	\[ g(y) = \frac{1}{\MP(Y = y)} \int_{\{\MP(Y=y)\}} X d\MP =: \ME[X|Y=y].\]
	В большинстве случаев $\MP(Y=y)=0$.
\end{exmp}

\begin{defn}
	Пусть $X:\Omega \rightarrow \MR$ интегрируема и $Y:\Omega \rightarrow \Omega'$. Если $g$ удовлетворяет равенству (\ref{1.1}) и $\mathcal{A}'$-$\mathcal{B}$-измерима и $\MP^Y$-интегрируема, тогда
	\[ g(y) := \ME[X|Y=y] \]
	называется \textbf{\textit{математическим ожиданием $X$ при условии $Y=y$}}.
\end{defn}

\begin{rmrk}
	В общем случае, $\ME[X|Y]$ -- случайная величина, которая принимает различные значения в соответствии с реализацией $\omega \mapsto Y(\omega)$. В свою очередь, $\ME[X|Y=y]$ -- вещественное число, принадлежащее реализации $Y(\omega)=y$.
\end{rmrk}

\begin{exmp}
	Мы уже посчитали $\ME[X|Y]$ в двух важных случаях (см. Пример \ref{exmp1.16}):
	\begin{enumerate}
		\item Для дискретных случайных величин $X$ и $Y$, мы получаем:
		\[ \ME[X|Y=y] = g(y)=
		\left \{
		\begin{array}{cl}
		\sum_{x \in I_X} x \frac{p_{xy}}{p_y}, & p_y > 0, \\
		0, & p_y = 0.
		\end{array}
		\right.
		\]
		\item Для непрерывных:
		\[ \ME[X|Y=y] = g(y)=
		\left \{
		\begin{array}{cl}
		\int x \frac{f_{X,Y}(x, y)}{f_Y(y)} , & f_Y(y) > 0, \\
		0, & f_Y(y) = 0.
		\end{array}
		\right.
		\]
	\end{enumerate}
	Оба равенства схожи с формулами для стандартного математического ожидания, за исключением того, что мы замещаем $p_x$ и $f_X(x)$ их условными версиями:
	\[\MP(X=x|Y=y) = \frac{p_{xy}}{p_y} \quad \text{и} \quad f_{X|Y}(x,y)=\frac{f_{X,Y}(x,y)}{f_Y(y)}.\]
	Если $X$ и $Y$ независимы, то мы получаем обыкновенное математическое ожидание (см. Следствие \ref{crlr1.15}).
\end{exmp}

\begin{rmrk}
	В начале главы, мы заметили, что $\ME[X|\mathcal{F}]$ -- лучшая аппроксимация $X$ при условии $\mathcal{F}$. Давайте, опишем это строго.
\end{rmrk}

\begin{thm}
	Пусть $X \in L^2(\Omega, \mathcal{A}, \MP)$. Тогда для любой случайной величины $Y \in L^2(\Omega, \mathcal{F}, \MP)$ соблюдается неравенство
	\[ \ME[(X - Y)^2] \geq \ME[(X- \ME[X|\mathcal{F}])^2], \]
	которое вырождается в равенство тогда и только тогда, когда $Y=\ME[X|\mathcal{F}]$ п.н.
\end{thm}
\begin{proof}
	Из условного неравенства Йенсена и Следствия \ref{crlr1.15} следует:
	\[ \ME[(\ME[X|\mathcal{F}])^2] \leq \ME[\ME[X^2|\mathcal{F}]] = \ME[X^2] < \infty. \]
	Далее, используя Следствие \ref{crlr1.15} и Теорему \ref{Factorization theorem}, получаем
	\[ \ME[XY]=\ME[\ME[XY|\mathcal{F}]] = \ME[Y\ME[X|\mathcal{F}]] \]
    и
	\[ \ME[X\ME[X|\mathcal{F}]] = \ME[\ME[X\ME[X|\mathcal{F}]]] = \ME[\ME[X^2|\mathcal{F}]]. \]
	Следовательно,
	\[ 
	\begin{aligned}
	    \ME[(X-Y)^2]-\ME[(X-\ME[X|\mathcal{F}])^2] &= \ME[X^2-2XY+Y^2]-\ME[X^2-2X\ME[X|\mathcal{F}]+(\ME[X|\mathcal{F}])^2] \\
	    & = \ME[Y^2-2\ME[Y\ME[X|\mathcal{F}]]+(\ME[X|\mathcal{F}])^2] \\
	    & = \ME[(Y - \ME[X|\mathcal{F}])^2] \geq 0.
	\end{aligned}
	\]
\end{proof}


\raggedbottom
\pagebreak

\section*{Упражнения}
\begin{exc}
	Пусть $X$ -- конечная интегрируемая вещественнозначная случайная величина, заданная на вероятностном пространстве $(\Omega, \mathcal{A}, \MP)$ и $\mathcal{F} \subset \mathcal{A}$ -- $\sigma$-алгебра.
	\begin{enumerate}
		\item Докажите \textbf{\textit{условное неравенство Йенсена}}: для любой выпуклой функции $\varphi: \MR \rightarrow \MR$
		\[ \varphi(\ME[X|\mathcal{F}]) \leq \ME[\varphi(X)|\mathcal{F}] \quad \MP\text{-п.н.} \]
		\textit{Подсказка}: для любой выпуклой функции $\varphi: \MR \rightarrow \MR$ существует последовательность $(a_n, b_n)_{n \in \MN} \subset \MR^2$, такая что равенство
		\[ \varphi = \sup_{(a_n, b_n)}(a_n x + b_n) \]
		соблюдается $\forall x \in \MR$.
		\item Докажите, что
		\[ \| \ME[X|\mathcal{F}] \|_p \leq \|X \|_p \quad \forall p \geq 1,  \]
		где $ \| \cdot \|_p = (\ME[|\cdot|^p])^{1/p} $.
	\end{enumerate}
\end{exc}

\begin{exc}
	Пусть $X$ -- вещественнозначная случайная величина, заданная на вероятностном пространстве $(\Omega, \mathcal{A}, \MP)$ и $\mathcal{F} \subset \mathcal{A}$ -- $\sigma$-алгебра. \textbf{\textit{Условная дисперсия}} задается следующим образом:
	\[\Var(X|\mathcal{F}):=\ME[(X-\ME[X|\mathcal{F}])^2|\mathcal{F}].  \]
	Покажите, что
	\[\Var(X)=\ME[\Var(X|\mathcal{F})]+\Var(\ME[X]|\mathcal{F}).\]
\end{exc}

\begin{exc}
	Пусть $X =(X_1, X_2)^T \in \MR^2$ -- двумерный нормально распределенный случайный вектор: $X \sim \mathcal{N}(\mu, \Sigma)$, с математическим ожиданием $\mu = (0,0)^T$ и ковариационной матрицей \[ \Sigma = \begin{pmatrix}
	\sigma_1^2 & \rho \sigma_1 \sigma_2 \\
	\rho \sigma_1 \sigma_2 & \sigma_2^2
	\end{pmatrix}.\] Покажите, что
	\[ \ME[X_1 | X_2] = \rho \frac{\sigma_1}{\sigma_2}X_2. \]
\end{exc}

\begin{exc}
	Пусть $X,Y$ -- две случайные величины с совместной плотностью
	\[ f_{X, Y}(x, y)=\lambda^2 e^{-\lambda x} 1_{(0, \infty)}(x-y)1_{(0, \infty)}(y). \]
	\begin{enumerate}
		\item Найдите маргинальные плотности $f_X$ и $f_Y$. Что это за распределения?
		\item Вычислите $\ME[Y|X]$.
		\item Покажите, что $\ME[\ME[Y|X]]=\ME[Y]$.
	\end{enumerate}
\end{exc}

\begin{exc}
	Пусть $X$ и $Y$ -- две вещественнозначные случайные величины, заданные на вероятностном пространстве $(\Omega, \mathcal{A}, \MP)$ и $\varphi: \Omega \times \Omega \rightarrow \MR$ -- $\mathcal{A}$-$\mathcal{A}$-измеримая функция. Покажите с помощью теоремы Фубини, что для функции $g: x \mapsto \ME[\varphi(x,Y)]$ выполняется равенство
	\[g(X) = \ME[\varphi(X, Y)|X] \quad \MP\text{-п.н.}\]
\end{exc}